# CÃ i Ä‘áº·t kÃ­ch thÆ°á»›c áº£nh vÃ  batch size
height, width = 224, 224
batch_size = 64

# ğŸ” TÃ¬m Ä‘Ãºng Ä‘Æ°á»ng dáº«n dataset (tá»± Ä‘á»™ng)
def find_dataset_path(base="/kaggle/input"):
    for dirname, _, filenames in os.walk(base):
        if "Covid19-dataset" in dirname:
            train_path = os.path.join(dirname, "train")
            test_path = os.path.join(dirname, "test")
            if os.path.exists(train_path) and os.path.exists(test_path):
                return train_path, test_path
    raise FileNotFoundError("KhÃ´ng tÃ¬m tháº¥y folder chá»©a Covid19-dataset/train vÃ  test!")

TRAIN_VAL_DIR, TEST_DIR = find_dataset_path()

# âš™ï¸ Chuáº©n bá»‹ dá»¯ liá»‡u
def generate_data(DIR, subset=None):
    datagen = ImageDataGenerator(
        rescale=1./255,
        validation_split=0.2 if subset in ['training', 'validation'] else None
    )
    
    generator = datagen.flow_from_directory(
        DIR,
        batch_size=batch_size,
        shuffle=True,
        seed=42,
        class_mode='categorical',
        target_size=(height, width),
        subset=subset
    )
    return generator

# ğŸš€ Táº¡o generators
train_generator = generate_data(TRAIN_VAL_DIR, subset='training')
validation_generator = generate_data(TRAIN_VAL_DIR, subset='validation')
test_generator = generate_data(TEST_DIR)

# ğŸ“Š Thá»‘ng kÃª sá»‘ lÆ°á»£ng áº£nh
total_image = np.concatenate([train_generator.labels, validation_generator.labels])
print('\\n\\n', {
    'Normal_cases': len(np.where(total_image == 0)[0]),
    'Viral_Pneumonia_cases': len(np.where(total_image == 1)[0]),
    'Covid_cases': len(np.where(total_image == 2)[0])
})
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input
from tensorflow.keras.optimizers import Adam

def get_model():
    input_tensor = Input(shape=(height, width, 3))
    
    # Backbone: dÃ¹ng mÃ´ hÃ¬nh Ä‘Ã£ pretrained trÃªn ImageNet
    base_model = MobileNetV2(input_tensor=input_tensor, include_top=False, weights='imagenet')

    # KhÃ´ng train láº¡i pháº§n backbone
    base_model.trainable = False
    
    # Head má»›i cho task 3 lá»›p
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.3)(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.5)(x)
    output = Dense(3, activation='softmax')(x)
    
    model = Model(inputs=input_tensor, outputs=output)
    
    model.compile(optimizer=Adam(),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
    return model

    history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size,
    epochs=70,  # Sá»‘ lÆ°á»£ng epoch, cÃ³ thá»ƒ thay Ä‘á»•i Ä‘á»ƒ phÃ¹ há»£p vá»›i dá»¯ liá»‡u
    verbose=1
)

# LÆ°u mÃ´ hÃ¬nh sau khi huáº¥n luyá»‡n
model.save('/kaggle/working/model_covid_classifier.h5')

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p validation
_, acc = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size, verbose=0)
print(f'Model accuracy on validation data: {acc * 100.0:.3f}%')

# Váº½ biá»ƒu Ä‘á»“ accuracy vÃ  loss theo tá»«ng epoch
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()